## Reproduction: Detecting memorization and reasoning in LLMs

This directory reproduces the core experiments from the following papers:
- ðŸ“„ Xie et al, 2024 - [On Memorization of Large Language Models in Logical Reasoning](https://arxiv.org/abs/2410.23123)
    - [Code](https://github.com/AlphaPav/mem-kk-logic)
- ðŸ“„ Salido et al., 2025 â€” [None of the Others: a General Technique to Distinguish Reasoning from Memorization in Multiple-Choice LLM Evaluation Benchmarks](https://arxiv.org/abs/2502.12896)
- ðŸ“„ Wu et al., 2023 â€” [Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks](https://arxiv.org/abs/2307.02477)
    - [Code](https://github.com/ZhaofengWu/counterfactual-evaluation )
- ðŸ“„ Jin et al., 2024 â€“ [Disentangling Memory and Reasoning Ability in Large Language Models](https://arxiv.org/abs/2411.13504)
    - [Code](https://github.com/MingyuJ666/)Disentangling-Memory-and-Reasoning
- ðŸ“„ Hong et al., 2025 â€“ [The Reasoning-Memorization Interplay Is Mediated by a Single Direction](https://arxiv.org/abs/2503.23084)
    - [Code](https://github.com/yihuaihong/Linear_Reasoning_Features)



